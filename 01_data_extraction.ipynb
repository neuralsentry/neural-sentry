{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import concurrent.futures\n",
    "\n",
    "import pandas as pd\n",
    "from git import Repo, Commit\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPO_LIST = \"./data/repos.txt\"\n",
    "DESTINATION = \"./data/commits.csv\"\n",
    "SINCE = \"2015-01-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone/Pull Repos\n",
    "def clone_or_pull_repo(remote_url: str):\n",
    "    repo_name = remote_url.split(\"/\")[-1]\n",
    "    owner_name = remote_url.split(\"/\")[-2]\n",
    "    destination = f\"data/repos/{owner_name}/{repo_name}\"\n",
    "\n",
    "    repo = None\n",
    "    if os.path.exists(destination):\n",
    "        repo = Repo(destination)\n",
    "        print(f\"Pulling {repo_name}\")\n",
    "        repo.remotes.origin.pull()\n",
    "        print(f\"[DONE] Pulling {repo_name}\")\n",
    "    else:\n",
    "        print(f\"Cloning {repo_name}\")\n",
    "        repo = Repo.clone_from(remote_url, destination)\n",
    "        print(f\"[DONE] Cloning {repo_name}\")\n",
    "\n",
    "    return repo\n",
    "\n",
    "\n",
    "repo_list = []\n",
    "with open(REPO_LIST) as f:\n",
    "    for line in f:\n",
    "        repo_list.append(line.strip())\n",
    "\n",
    "repos = []\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
    "    repos = executor.map(clone_or_pull_repo, repo_list)\n",
    "repos = list(repos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exporting commits to ./data/commits.csv: 100%|██████████| 183108/183108 [2:35:51<00:00, 19.58it/s]  \n"
     ]
    }
   ],
   "source": [
    "# Batched Export\n",
    "def add_commits_to_csv(\n",
    "    commits: list[Commit],\n",
    "    destination: str,\n",
    "    write_header: bool = False,\n",
    "    batch_size: int = 20,\n",
    "    pbar: tqdm = None,\n",
    "):\n",
    "    for i in range(0, len(commits), batch_size):\n",
    "        batch = commits[i : i + batch_size]\n",
    "        outputs = []\n",
    "        for commit in batch:\n",
    "            parent = commit.parents[0] if commit.parents else None\n",
    "            if not parent:  # Skip first commit\n",
    "                continue\n",
    "\n",
    "            output = {\n",
    "                \"commit_msg\": commit.message,\n",
    "                \"sha\": commit.hexsha,\n",
    "                \"remote_url\": commit.repo.remotes.origin.url,\n",
    "                \"date\": commit.authored_datetime,\n",
    "                \"labels\": -1,\n",
    "            }\n",
    "\n",
    "            outputs.append(output)\n",
    "        df = pd.DataFrame(outputs)\n",
    "        df.to_csv(destination, mode=\"a\", index=False, header=write_header)\n",
    "        write_header = False\n",
    "\n",
    "        if pbar:\n",
    "            pbar.update(len(batch))\n",
    "\n",
    "\n",
    "commit_count = sum(1 for repo in repos for commit in repo.iter_commits(since=SINCE))\n",
    "\n",
    "with tqdm(total=commit_count, desc=f\"Exporting commits to {DESTINATION}\") as pbar:\n",
    "    is_file_exists = os.path.isfile(DESTINATION)\n",
    "    is_file_empty = is_file_exists and os.path.getsize(DESTINATION) == 0\n",
    "    write_header = not is_file_exists or is_file_empty\n",
    "\n",
    "    for repo in repos:\n",
    "        repo_name = repo.remotes.origin.url.split(\"/\")[-1].split(\".\")[0]\n",
    "        destination = f\"./data/{repo_name}.csv\"\n",
    "        commits = list(repo.iter_commits(since=SINCE))\n",
    "        add_commits_to_csv(\n",
    "            commits,\n",
    "            destination=DESTINATION,\n",
    "            write_header=write_header,\n",
    "            pbar=pbar,\n",
    "            batch_size=50,\n",
    "        )\n",
    "        write_header = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (E:/.cache/huggingface/datasets/csv/default-9f95ed729e084b78/0.0.0/6954658bab30a358235fa864b05cf819af0e179325c740e4bc853bcc7ec513e1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>commit_msg</th>\n",
       "      <th>sha</th>\n",
       "      <th>remote_url</th>\n",
       "      <th>date</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Update runner OS version for hardenedmalloc te...</td>\n",
       "      <td>8a6cd08850f576e7527c52a1b086cae82fab290e</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "      <td>2023-06-23 09:49:02+10:00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>handle sysconf(SC_OPEN_MAX) returning &gt; INT_MA...</td>\n",
       "      <td>cfca6f17e64baed6822bb927ed9f372ce64d9c5b</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "      <td>2023-06-22 15:04:03+10:00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>upstream: better validate CASignatureAlgorithm...</td>\n",
       "      <td>c1c2ca1365b3f7b626683690bd2c68265f6d8ffd</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "      <td>2023-06-21 05:10:26+00:00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>upstream: make `ssh -Q CASignatureAlgorithms` ...</td>\n",
       "      <td>4e73cd0f4ab3e5b576c56cac9732da62c8fc0565</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "      <td>2023-06-21 05:08:32+00:00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>upstream: handle rlimits &gt; INT_MAX (rlim_t is ...</td>\n",
       "      <td>a69062f1695ac9c3c3dea29d3044c72aaa6af0ea</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "      <td>2023-06-21 05:06:04+00:00</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          commit_msg  \\\n",
       "0  Update runner OS version for hardenedmalloc te...   \n",
       "1  handle sysconf(SC_OPEN_MAX) returning > INT_MA...   \n",
       "2  upstream: better validate CASignatureAlgorithm...   \n",
       "3  upstream: make `ssh -Q CASignatureAlgorithms` ...   \n",
       "4  upstream: handle rlimits > INT_MAX (rlim_t is ...   \n",
       "\n",
       "                                        sha  \\\n",
       "0  8a6cd08850f576e7527c52a1b086cae82fab290e   \n",
       "1  cfca6f17e64baed6822bb927ed9f372ce64d9c5b   \n",
       "2  c1c2ca1365b3f7b626683690bd2c68265f6d8ffd   \n",
       "3  4e73cd0f4ab3e5b576c56cac9732da62c8fc0565   \n",
       "4  a69062f1695ac9c3c3dea29d3044c72aaa6af0ea   \n",
       "\n",
       "                                    remote_url                       date  \\\n",
       "0  https://github.com/openssh/openssh-portable  2023-06-23 09:49:02+10:00   \n",
       "1  https://github.com/openssh/openssh-portable  2023-06-22 15:04:03+10:00   \n",
       "2  https://github.com/openssh/openssh-portable  2023-06-21 05:10:26+00:00   \n",
       "3  https://github.com/openssh/openssh-portable  2023-06-21 05:08:32+00:00   \n",
       "4  https://github.com/openssh/openssh-portable  2023-06-21 05:06:04+00:00   \n",
       "\n",
       "   labels  \n",
       "0      -1  \n",
       "1      -1  \n",
       "2      -1  \n",
       "3      -1  \n",
       "4      -1  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = load_dataset(\"csv\", data_files=DESTINATION, split=\"train\")\n",
    "raw_datasets.set_format(\"pandas\")\n",
    "df = raw_datasets.to_pandas()\n",
    "df.head()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "CgTBrgzeltDT"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
