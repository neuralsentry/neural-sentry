{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "df = pd.read_csv(\"data/commits.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>sha</th>\n",
       "      <th>remote_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fixup! if -s &amp; -p specified, mention 'sftp -p'...</td>\n",
       "      <td>2709809fd616a0991dc18e3a58dea10fb383c3f0</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>make ssh-copy-id(1) consistent with openssh.  ...</td>\n",
       "      <td>204e0bf05161b7641500d7ab266c21217412379f</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>if -s &amp; -p specified, mention 'sftp -p' on suc...</td>\n",
       "      <td>9de79df66d1430d290fab670bb4b18612875e518</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drop whitespace  ssh-copy-id-upstream: e604fae...</td>\n",
       "      <td>801cda54c00e0f4e7d89345a90874c8d05dc233a</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>make -x also apply to the target script  ssh-c...</td>\n",
       "      <td>288482f53613f3e74544eb92deeb24f7c7f1f371</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>remove skipping test when scp not in path.  an...</td>\n",
       "      <td>8a5e99a70fcf9b022a8aa175ebf6a71f58511da3</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>upstream: add a \"host\" line to the output of s...</td>\n",
       "      <td>41f36dd896c8fb8337d403fcf476762986976e9d</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>upstream: avoid printf(\"%s\", null) if using ss...</td>\n",
       "      <td>f673b49f3be3eb51074fbb8a405beb6cd0f7d93e</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>upstream: clamp the minimum buffer lengths and...</td>\n",
       "      <td>93fc7c576563e3d88a1dc019dd213f65607784cc</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>upstream: ignore bogus upload/download buffer ...</td>\n",
       "      <td>48bf234322e639d279c5a28435eae50155e9b514</td>\n",
       "      <td>https://github.com/openssh/openssh-portable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               message  \\\n",
       "0    fixup! if -s & -p specified, mention 'sftp -p'...   \n",
       "1    make ssh-copy-id(1) consistent with openssh.  ...   \n",
       "2    if -s & -p specified, mention 'sftp -p' on suc...   \n",
       "3    drop whitespace  ssh-copy-id-upstream: e604fae...   \n",
       "4    make -x also apply to the target script  ssh-c...   \n",
       "..                                                 ...   \n",
       "199  remove skipping test when scp not in path.  an...   \n",
       "200  upstream: add a \"host\" line to the output of s...   \n",
       "201  upstream: avoid printf(\"%s\", null) if using ss...   \n",
       "202  upstream: clamp the minimum buffer lengths and...   \n",
       "203  upstream: ignore bogus upload/download buffer ...   \n",
       "\n",
       "                                          sha  \\\n",
       "0    2709809fd616a0991dc18e3a58dea10fb383c3f0   \n",
       "1    204e0bf05161b7641500d7ab266c21217412379f   \n",
       "2    9de79df66d1430d290fab670bb4b18612875e518   \n",
       "3    801cda54c00e0f4e7d89345a90874c8d05dc233a   \n",
       "4    288482f53613f3e74544eb92deeb24f7c7f1f371   \n",
       "..                                        ...   \n",
       "199  8a5e99a70fcf9b022a8aa175ebf6a71f58511da3   \n",
       "200  41f36dd896c8fb8337d403fcf476762986976e9d   \n",
       "201  f673b49f3be3eb51074fbb8a405beb6cd0f7d93e   \n",
       "202  93fc7c576563e3d88a1dc019dd213f65607784cc   \n",
       "203  48bf234322e639d279c5a28435eae50155e9b514   \n",
       "\n",
       "                                      remote_url  \n",
       "0    https://github.com/openssh/openssh-portable  \n",
       "1    https://github.com/openssh/openssh-portable  \n",
       "2    https://github.com/openssh/openssh-portable  \n",
       "3    https://github.com/openssh/openssh-portable  \n",
       "4    https://github.com/openssh/openssh-portable  \n",
       "..                                           ...  \n",
       "199  https://github.com/openssh/openssh-portable  \n",
       "200  https://github.com/openssh/openssh-portable  \n",
       "201  https://github.com/openssh/openssh-portable  \n",
       "202  https://github.com/openssh/openssh-portable  \n",
       "203  https://github.com/openssh/openssh-portable  \n",
       "\n",
       "[200 rows x 3 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def text_preprocessing(text):\n",
    "    text = text.lower() # Make all words lower case\n",
    "    text = re.sub('.*?(?:http|https)://[^\\s]+.*?', \"\", text) # Remove entire sentence if url detected\n",
    "    text = re.sub('\\n', ' ', text) # Remove newlines, replace with space\n",
    "    return text\n",
    "\n",
    "df = df.dropna(how='any') # Drop any na values\n",
    "df['message'] = df['message'].apply(str).apply(lambda x: text_preprocessing(x))\n",
    "df = df[df['message'].str.len() <= 512] # Remove any commits longer than 512 (change to your model's max context length)\n",
    "df.head(200)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified Random Sampling (disproportionate)\n",
    "An imbalanced dataset is a machine learning classification problem in which the two class labels in the target variable are not proportional to one another. In other words, one class has a higher count than the other, resulting in an imbalance.\n",
    "\n",
    "In machine learning, stratified sampling is also used to obtain the same sample proportion for a train and test set if there is an imbalance in the dataset.  \n",
    "\n",
    "Benefits\n",
    "- Ensure adequate amount of data for the smallest group (nginx)\n",
    "- Evenly divide total sample size between subgroups\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/apache/httpd: 32270\n",
      "https://github.com/nginx/nginx: 7621\n",
      "https://github.com/openssh/openssh-portable: 11964\n",
      "https://github.com/openssl/openssl: 31082\n"
     ]
    }
   ],
   "source": [
    "# Number of entries per repo\n",
    "repo_types = np.unique(df['remote_url'].tolist())\n",
    "for repo in repo_types:\n",
    "    print(f\"{repo}: {len(df[df['remote_url'] == repo])}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating sample dataset with 5000 commits per repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df = df.groupby(\"remote_url\",group_keys=False).apply(lambda x:x.sample(n=5000, random_state=6)) # random_state is a seed\n",
    "# openssl_samples = sample_df.loc[df['remote_url'] == \"https://github.com/openssl/openssl\"]\n",
    "sample_df.to_csv(\"test.csv\")\n",
    "len(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, DataCollatorForLanguageModeling\n",
    "import torch\n",
    "from datasets import Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['message'],\n",
       "    num_rows: 120637\n",
       "})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.remove_columns(['sha','remote_url'])\n",
    "dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7bcae62a7849c3bd86f7e104cb4ac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'message': 'log an error if bio_write(3) fails\\n\\n\\ngit-svn-id: https://svn.apache.org/repos/asf/httpd/httpd/trunk@1910269 13f79535-47bb-0310-9956-ffa450edef68\\n',\n",
       " 'input_ids': [0,\n",
       "  12376,\n",
       "  41,\n",
       "  5849,\n",
       "  114,\n",
       "  10709,\n",
       "  1215,\n",
       "  29631,\n",
       "  1640,\n",
       "  246,\n",
       "  43,\n",
       "  10578,\n",
       "  50140,\n",
       "  50118,\n",
       "  20901,\n",
       "  12,\n",
       "  36245,\n",
       "  282,\n",
       "  12,\n",
       "  808,\n",
       "  35,\n",
       "  1205,\n",
       "  640,\n",
       "  36245,\n",
       "  282,\n",
       "  4,\n",
       "  48530,\n",
       "  4,\n",
       "  1957,\n",
       "  73,\n",
       "  241,\n",
       "  11474,\n",
       "  73,\n",
       "  281,\n",
       "  506,\n",
       "  73,\n",
       "  8166,\n",
       "  417,\n",
       "  73,\n",
       "  8166,\n",
       "  417,\n",
       "  73,\n",
       "  4328,\n",
       "  6435,\n",
       "  1039,\n",
       "  1646,\n",
       "  698,\n",
       "  31416,\n",
       "  508,\n",
       "  506,\n",
       "  36346,\n",
       "  2022,\n",
       "  12,\n",
       "  3706,\n",
       "  14141,\n",
       "  12,\n",
       "  3933,\n",
       "  698,\n",
       "  12,\n",
       "  2831,\n",
       "  4419,\n",
       "  12,\n",
       "  3145,\n",
       "  102,\n",
       "  13872,\n",
       "  196,\n",
       "  4550,\n",
       "  4671,\n",
       "  50118,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"microsoft/codebert-base\" # Change model name to your model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "context_length = 512 # Change to your model max context length\n",
    "\n",
    "def tokenize_pad_and_truncate(texts):\n",
    "    return tokenizer(texts['message'], truncation=True, padding=\"max_length\", max_length=context_length)\n",
    "\n",
    "tokenized_dataset = dataset.map(tokenize_pad_and_truncate, batched=True)\n",
    "tokenized_dataset[0]\n",
    "\n",
    "\n",
    "# inputs = tokenizer('Fix: bug racing event', return_tensors='pt', max_length=5, truncation=True, padding='max_length')\n",
    "# print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': 'log an error if BIO_write(3) fails\\n\\n\\ngit-svn-id: https://svn.apache.org/repos/asf/httpd/httpd/trunk@1910269 13f79535-47bb-0310-9956-ffa450edef68\\n'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_pandas(df)\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
